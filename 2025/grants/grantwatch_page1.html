from bs4 import BeautifulSoup
import pandas as pd
import os

script_dir = os.path.dirname(os.path.abspath(__file__))
html_path = os.path.join(script_dir, "grantwatch_page1.html")

with open(html_path, "r", encoding="utf-8") as f:
	soup = BeautifulSoup(f, "html.parser")

grants = []
cards = soup.find_all("div", class_="grantCard")

for card in cards:
	title_tag = card.find("a", class_="grantTitle")
	desc_tag = card.find("div", class_="grantDescription")
	if title_tag:
		title = title_tag.get_text(strip=True)
		url = "https://www.grantwatch.com" + title_tag.get("href")
		description = desc_tag.get_text(strip=True) if desc_tag else ""
		grants.append({
			"url": url,
			"title": title,
			"description": description
		})

df = pd.DataFrame(grants)
csv_path = os.path.join(script_dir, "grantwatch_extracted.csv")
df.to_csv(csv_path, index=False)
print(f" Extracted {len(df)} grants from saved page to: {csv_path}")
