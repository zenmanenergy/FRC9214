import cv2
import numpy as np
import math

# Load camera matrix and distortion coefficients
camera_matrix = np.load('cameramatrix.npy')
dist_coeffs = np.load('dist.npy')

# Define ArUco dictionary and parameters
aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_APRILTAG_36h11)  # 6x6 ArUco dictionary
parameters = cv2.aruco.DetectorParameters()

# Define the size of the ArUco marker (in meters)
marker_size = 0.164  # meters, adjust if necessary based on the actual size of the ArUco marker

# Capture video or load image
cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # Replace with 'image_path' if loading an image

cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
while True:
    ret, frame = cap.read()  # Capture frame
    if not ret:
        break

    # Convert to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect markers in the image
    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

    if len(corners) > 0:
        # Draw detected markers
        frame = cv2.aruco.drawDetectedMarkers(frame, corners, ids)

        # Estimate pose of detected markers
        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, marker_size, camera_matrix, dist_coeffs)

        for i in range(len(ids)):
            # Draw axis for each marker
            cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvecs[i], tvecs[i], 0.1)

            # Get translation and rotation vectors
            tvec = tvecs[i]
            rvec = rvecs[i]

            # Compute distance (m)
            distance = np.linalg.norm(tvec)
            
            # Compute Euler angles from the rotation vector (rvec)
            rotation_matrix, _ = cv2.Rodrigues(rvec)
            
            # Compute Euler angles (pitch, yaw, roll)
            sy = math.sqrt(rotation_matrix[0, 0] ** 2 + rotation_matrix[1, 0] ** 2)
            singular = sy < 1e-6
            if not singular:
                pitch = math.atan2(rotation_matrix[2, 1], rotation_matrix[2, 2])
                yaw = math.atan2(-rotation_matrix[2, 0], sy)
                roll = math.atan2(rotation_matrix[1, 0], rotation_matrix[0, 0])
            else:
                pitch = math.atan2(-rotation_matrix[1, 2], rotation_matrix[1, 1])
                yaw = 0
                roll = math.atan2(-rotation_matrix[2, 0], sy)

            # Display the results
            cv2.putText(frame, f"Distance: {distance:.2f} m", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, f"Yaw: {yaw * 180 / math.pi:.2f}°", (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, f"Pitch: {pitch * 180 / math.pi:.2f}°", (50, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, f"Roll: {roll * 180 / math.pi:.2f}°", (50, 140), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
    # Show the frame with the detected marker and pose
    cv2.imshow("ArUco Marker Detection", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
